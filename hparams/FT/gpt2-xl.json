{
    "layers": [13, 14, 15, 16, 17],
    "num_steps": 25,
    "lr": 2e-5,
    "weight_decay": 0.5,
    "kl_factor": 0.0625,
    "norm_constraint": 1e-3,
    "rewrite_module_tmp": "transformer.h.{}.attn.c_attn",
    "layer_module_tmp": "transformer.h.{}",
    "mlp_module_tmp": "transformer.h.{}.mlp",
    "attn_module_tmp": "transformer.h.{}.attn",
    "ln_f_module": "transformer.ln_f",
    "lm_head_module": "transformer.wte"
}